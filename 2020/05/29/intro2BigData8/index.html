<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>大数据技术原理与应用 - (8). Hive - 基于 Hadoop 的数据仓库 - Zhanhang Zeng&#039;s Blog | 小树的个人博客</title><meta description="【第三篇】 - 大数据处理与分析, 《大数据技术原理与应用, 林子雨》 本篇介绍大数据处理与分析的相关技术，包括  第7章 - MapReduce 第8章 - Hive - 基于 Hadoop 的数据仓库 第9章 - Hadoop 的优化与发展 第10章 - Spark 第11章 - 流计算 第12章 - 图计算 第13章 - 数据可视化  Hive 是一个基于 Hadoop 的数据仓库平台。通"><meta property="og:type" content="blog"><meta property="og:title" content="大数据技术原理与应用 - (8). Hive - 基于 Hadoop 的数据仓库"><meta property="og:url" content="https://zengzhanhang.com/2020/05/29/intro2BigData8/"><meta property="og:site_name" content="Zhanhang Zeng&#039;s Blog | 小树的个人博客"><meta property="og:description" content="【第三篇】 - 大数据处理与分析, 《大数据技术原理与应用, 林子雨》 本篇介绍大数据处理与分析的相关技术，包括  第7章 - MapReduce 第8章 - Hive - 基于 Hadoop 的数据仓库 第9章 - Hadoop 的优化与发展 第10章 - Spark 第11章 - 流计算 第12章 - 图计算 第13章 - 数据可视化  Hive 是一个基于 Hadoop 的数据仓库平台。通"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://zengzhanhang.com/notes/BigData/assets/thumbnail.jpg"><meta property="article:published_time" content="2020-05-29T15:34:59.000Z"><meta property="article:modified_time" content="2020-06-01T10:45:43.947Z"><meta property="article:author" content="Zhanhang (Kyle) ZENG"><meta property="article:tag" content="Big Data"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/notes/BigData/assets/thumbnail.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://zengzhanhang.com/2020/05/29/intro2BigData8/"},"headline":"Zhanhang Zeng's Blog | 小树的个人博客","image":["https://zengzhanhang.com/notes/BigData/assets/thumbnail.jpg"],"datePublished":"2020-05-29T15:34:59.000Z","dateModified":"2020-06-01T10:45:43.947Z","author":{"@type":"Person","name":"Zhanhang (Kyle) ZENG"},"description":"【第三篇】 - 大数据处理与分析, 《大数据技术原理与应用, 林子雨》 本篇介绍大数据处理与分析的相关技术，包括  第7章 - MapReduce 第8章 - Hive - 基于 Hadoop 的数据仓库 第9章 - Hadoop 的优化与发展 第10章 - Spark 第11章 - 流计算 第12章 - 图计算 第13章 - 数据可视化  Hive 是一个基于 Hadoop 的数据仓库平台。通"}</script><link rel="canonical" href="https://zengzhanhang.com/2020/05/29/intro2BigData8/"><link rel="icon" href="/img/thumbnail.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-dark.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?3a6a069adc986db638814c1b4a9e5ce6";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-167464294-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-167464294-1');</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css"><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><script type="text/javascript" src="/js/imaegoo/night.js"></script><canvas id="universe"></canvas><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img class="logo-img" src="/img/logo_light.png" alt="Zhanhang Zeng&#039;s Blog | 小树的个人博客" height="28"><img class="logo-img-dark" src="/img/logo_dark.png" alt="Zhanhang Zeng&#039;s Blog | 小树的个人博客" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/notes_TOC">Notes - 数据科学知识手册</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Zhanhang&#039;s GitHub" href="https://github.com/zengzhanhang"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="thumbnail" src="/notes/BigData/assets/thumbnail.jpg" alt="大数据技术原理与应用 - (8). Hive - 基于 Hadoop 的数据仓库"></span></div><article class="card-content article" role="article"><h1 class="title is-3 is-size-4-mobile">大数据技术原理与应用 - (8). Hive - 基于 Hadoop 的数据仓库</h1><div class="article-meta size-small is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time class="level-item" dateTime="2020-05-29T15:34:59.000Z" title="2020-05-29T15:34:59.000Z">2020-05-29</time></span><span class="level-item"><i class="far fa-calendar-check"> </i><time class="level-item" dateTime="2020-06-01T10:45:43.947Z" title="2020-06-01T10:45:43.947Z">Edit: 2020-06-01</time></span><span class="level-item"><i class="fas fa-user"> </i>Zhanhang (Kyle) ZENG</span><span class="level-item"><i class="far fa-clock"></i> 26 minutes read (About 3915 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="busuanzi_value_page_pv">0</span> visits</span></div><div class="level-left is-uppercase mt-2"><span class="level-item"><i class="fas fa-folder-open has-text-grey"></i> <a class="link-muted" href="/categories/Big-Data/">Big Data</a></span><span class="level-item"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/Big-Data/">Big Data</a></span></div></div><div class="content"><div class="notification is-warning">
<p><strong>【第三篇】 - 大数据处理与分析</strong>, 《大数据技术原理与应用, 林子雨》</p>
<p>本篇介绍大数据处理与分析的相关技术，包括</p>
<ul>
<li>第7章 - <a href="#">MapReduce</a></li>
<li>第8章 - <a href="#"><strong>Hive - 基于 Hadoop 的数据仓库</strong></a></li>
<li>第9章 - <a href="#">Hadoop 的优化与发展</a></li>
<li>第10章 - <a href="#">Spark</a></li>
<li>第11章 - <a href="#">流计算</a></li>
<li>第12章 - <a href="#">图计算</a></li>
<li>第13章 - <a href="#">数据可视化</a></li>
</ul>
<p>Hive 是一个基于 Hadoop 的数据仓库平台。通过 Hive，我们可以方便地进行 ETL 的工作。Hive 定义了一个类似于 SQL 的查询语言: HiveQL，能够将用户编写的 HiveQL 转化为相应的 Mapreduce 程序基于 Hadoop 执行，可以说 Hive 实质就是一款基于 HDFS 的 MapReduce 计算框架，对存储在 HDFS 中的数据进行分析和管理。</p>
</div>
<a id="more"></a>
<h1 id="Hive-概述"><a href="#Hive-概述" class="headerlink" title="Hive 概述"></a>Hive 概述</h1><h2 id="数据仓库概念"><a href="#数据仓库概念" class="headerlink" title="数据仓库概念"></a>数据仓库概念</h2><p>数据仓库 (Data Warehouse) 是一个面向主题的 (Subject Oriented)、集成的 (Integrated)、相对稳定的 (Non-Volatile)、反映历史变化 (Time Variant) 的数据集合，用于支持管理决策。</p>
<div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch8/数据仓库的体系结构.png" alt="数据仓库的体系结构" title="数据仓库的体系结构" style="width: 100%;"/><br></div>

<p><strong>传统数据仓库面临的挑战</strong></p>
<ol>
<li>无法满足快速增长的海量数据存储需求</li>
<li>无法有效处理不同类型的数据</li>
<li>计算和处理能力不足</li>
</ol>
<h2 id="Hive-简介"><a href="#Hive-简介" class="headerlink" title="Hive 简介"></a>Hive 简介</h2><ul>
<li>Hive 是一个构建于 Hadoop 顶层的数据仓库工具</li>
<li>支持大规模数据存储、分析，具有良好的可扩展性</li>
<li>某种程度上可以看作是用户编程接口，本身不存储和处理数据</li>
<li><strong>依赖分布式文件系统 HDFS 存储数据</strong></li>
<li><strong>依赖分布式并行计算模型 MapReduce 处理数据</strong></li>
<li>定义了简单的类似 SQL 的查询语言 —— HiveQL</li>
<li>用户可以通过编写的 HiveQL 语句运行 MapReduce 任务</li>
<li>可以很容易把原来构建在关系数据库上的数据仓库应用程序移植到 Hadoop 平台上</li>
<li>是一个可以提供有效、合理、直观组织和使用数据的分析工具</li>
</ul>
<h2 id="Hive-特点"><a href="#Hive-特点" class="headerlink" title="Hive 特点"></a>Hive 特点</h2><p>Hive 具有的特点非常适用于数据仓库</p>
<ol>
<li><strong>采用批处理方式处理海量数据</strong><ul>
<li>Hive 需要把 HiveQL 语句转换成 MapReduce 任务进行运行</li>
<li>数据仓库存储的是静态数据，对静态数据的分析适合采用批处理方式，不需要快速响应给出结果，而且数据本身也不会频繁变化</li>
</ul>
</li>
<li><strong>提供适合数据仓库操作的工具</strong><ul>
<li>Hive 本身提供了一系列对数据进行提取、转换、加载 (ETL) 的工具，可以存储、查询和分析存储在 Hadoop 中的大规模数据</li>
<li>这些工具能够很好地满足数据仓库各种应用场景</li>
</ul>
</li>
</ol>
<ul>
<li><strong>优点</strong>：<ol>
<li><strong>可扩展性,横向扩展</strong>，Hive 可以自由的扩展集群的规模，一般情况下不需要重启服务 横向扩展：通过分担压力的方式扩展集群的规模 纵向扩展：一台服务器 cpu i7-6700k 4 核心 8 线程，8 核心 16 线程，内存 64G =&gt; 128G</li>
<li><strong>延展性</strong>，Hive 支持自定义函数，用户可以根据自己的需求来实现自己的函数</li>
<li><strong>良好的容错性</strong>，可以保障即使有节点出现问题，SQL 语句仍可完成执行</li>
</ol>
</li>
<li><strong>缺点</strong>：<ol>
<li><strong>Hive 不支持记录级别的增删改操作</strong>，但是用户可以通过查询生成新表或者将查询结 果导入到文件中 (当前选择的 hive-2.3.2 的版本支持记录级别的插入操作)</li>
<li><strong>Hive 的查询延时很严重</strong>，因为 MapReduce Job 的启动过程消耗很长时间，所以不能 用在交互查询系统中。</li>
<li><strong>Hive 不支持事务</strong> (因为不没有增删改，所以主要用来做 OLAP (联机分析处理)，而不是 OLTP (联机事务处理)，这就是数据处理的两大级别)。</li>
</ol>
</li>
</ul>
<div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch8/Hadoop生态系统.png" alt="Hadoop 生态系统" title="Hadoop 生态系统" style="width: 50%;"/><br></div>

<h2 id="Hive-和-RDBMS-的对比"><a href="#Hive-和-RDBMS-的对比" class="headerlink" title="Hive 和 RDBMS 的对比"></a>Hive 和 RDBMS 的对比</h2><div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch8/Hive与RDBMS的对比.png" alt="Hive 与 RDBMS 的对比 <sup>【Credit: https://www.cnblogs.com/qingyunzong/p/8707885.html】</sup>" title="Hive 与 RDBMS 的对比" style="width: 90%;"/><br></div>

<p>总结：</p>
<ul>
<li>Hive 具有 SQL 数据库的外表，但应用场景完全不同，<strong>Hive 只适合用来做海量离线数 据统计分析，也就是数据仓库</strong>。</li>
</ul>
<h2 id="Hive在企业中的部署和应用"><a href="#Hive在企业中的部署和应用" class="headerlink" title="Hive在企业中的部署和应用"></a>Hive在企业中的部署和应用</h2><div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch8/大数据分析部署框架.png" alt="企业中一种常见的大数据分析平台部署框架" title="企业中一种常见的大数据分析平台部署框架" style="width: 60%;"/><br></div>

<ul>
<li>Hive 批处理，时延高，报表不需要实时出结果。</li>
<li>HBase 可以实时反馈。</li>
<li>Mahout 中实现和提供了很多机器学习的 api，帮助企业分析人员能够快速构建商业智能应用。</li>
<li>HDFS：分布式文件存储；MapReduce：分布式数据处理</li>
</ul>
<h1 id="Hive-Design"><a href="#Hive-Design" class="headerlink" title="Hive Design"></a>Hive Design</h1><h2 id="Hive-Architecture"><a href="#Hive-Architecture" class="headerlink" title="Hive Architecture"></a>Hive Architecture</h2><div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch8/HiveArchitecture.png" alt="Hive Architecture Overview" title="Hive Architecture Overview" style="width: 100%;"/><br></div>

<ul>
<li>用户接口 (UI) 模块包括 CLI、HWI、JDBC、ODBC、Thrift Server</li>
<li>驱动模块 (Driver) 包括 Compiler、Optimizer、Execution Engine 等，负责把 HiveSQL 语句转换成一系列 MapReduce 作业</li>
<li>元数据 (metadata) 存储模块 (Metastore) 是一个独立的关系型数据库 (自带 derby 数据库，或 MySQL 数据库)</li>
</ul>

<div class="tabs is-toggle"><ul>
    <li class="is-active"><a onclick="onTabClick(event)">
    <span class="icon is-small"><i class="fas fa-book-open" aria-hidden="true"></i></span>
    <span>Source</span>
    </a></li>
    <li><a onclick="onTabClick(event)">
    <span class="icon is-small"><i class="fas fa-book-open" aria-hidden="true"></i></span>
    <span>中文翻译</span>
    </a></li>
</ul></div>


<div id="Source" class="tab-content" style="display: block;">
<blockquote>
<p>Apache Hive wiki: <a href="https://cwiki.apache.org/confluence/display/Hive/Design">https://cwiki.apache.org/confluence/display/Hive/Design</a></p>
</blockquote>
<p>Figure above shows the major components of Hive and its interactions with Hadoop. As shown in that figure, the main components of Hive are:</p>
<ul>
<li><strong>UI</strong> – The user interface for users to submit queries and other operations to the system. As of 2011 the system had a command line interface and a web based GUI was being developed.</li>
<li><strong>Driver</strong> – The component which receives the queries. This component implements the notion of session handles and provides execute and fetch APIs modeled on JDBC/ODBC interfaces.</li>
<li><strong>Compiler</strong> – The component that parses the query, does semantic analysis on the different query blocks and query expressions and eventually generates an execution plan with the help of the <code>table</code> and <code>partition metadata</code> looked up from the <code>metastore</code>.</li>
<li><strong>Metastore</strong> – The component that stores all the structure information of the various <code>tables</code> and <code>partitions</code> in the warehouse including column and column type information, the serializers and deserializers necessary to read and write data and the corresponding HDFS files where the data is stored.</li>
<li><strong>Execution Engine</strong> – The component which executes the execution plan created by the compiler. The plan is a DAG of stages. The execution engine manages the dependencies between these different stages of the plan and executes these stages on the appropriate system components.</li>
</ul>
<p>Figure also shows how a typical query flows through the system. The UI calls the execute interface to the Driver (step 1 in Figure 1). The Driver creates a session handle for the query and sends the query to the compiler to generate an execution plan (step 2). The compiler gets the necessary <code>metadata</code> from the <code>metastore</code> (steps 3 and 4). This <code>metadata</code> is used to typecheck the expressions in the query tree as well as to prune <code>partitions</code> based on query predicates. The plan generated by the compiler (step 5) is a DAG of stages with each stage being either a map/reduce job, a <code>metadata</code> operation or an operation on HDFS. For map/reduce stages, the plan contains map operator trees (operator trees that are executed on the mappers) and a reduce operator tree (for operations that need reducers). The execution engine submits these stages to appropriate components (steps 6, 6.1, 6.2 and 6.3). In each task (mapper/reducer) the deserializer associated with the <code>table</code> or intermediate outputs is used to read the rows from HDFS files and these are passed through the associated operator tree. Once the output is generated, it is written to a temporary HDFS file though the serializer (this happens in the mapper in case the operation does not need a reduce). The temporary files are used to provide data to subsequent map/reduce stages of the plan. For DML operations the final temporary file is moved to the <code>table</code>‘s location. This scheme is used to ensure that dirty data is not read (file rename being an atomic operation in HDFS). For queries, the contents of the temporary file are read by the execution engine directly from HDFS as part of the fetch call from the Driver (steps 7, 8 and 9).</p>
</div>
<div id="中文翻译" class="tab-content">
<p>上图展示了 Hive 的的主要组件以及它们与 Hadoop 的交互过程，这些 Hive 的主要组件包括:</p>
<ul>
<li><strong>UI</strong> - 用户界面。用于向系统提交查询和其他操作。截至2011年，该系统具有命令行界面，并且正在开发基于Web的GUI。</li>
<li><strong>Driver</strong> - 接收查询的组件。该组件实现了 session handle 的概念，并提供了以 JDBC / ODBC 接口为模型的 API 的执行和获取。</li>
<li><strong>Compiler</strong> - 解析查询的组件。对不同的查询块和查询表达式进行语义分析，并最终借助 <code>table</code> 和从 <code>metastore</code> 查找的 <code>partition metadata</code> (分区元数据) 来生成执行计划。</li>
<li><strong>Metastore</strong> - 该组件用于存储所有在仓库中的各种的 <code>tables</code> 和 <code>partitons</code> 的结构信息，包括列和列类型信息，读写数据所需的 serializers 和 deserializers 以及存储数据的相应 HDFS 文件。</li>
<li><strong>Execution Engine</strong> - 执行由 Compiler 创建的执行计划的组件。该计划是阶段的 DAG。Execution Engine 管理 execution plan 不同阶段之间的 dependencies，并在适当的系统组件上执行这些阶段。</li>
</ul>
<p>该图还展示了一个典型的查询如何在系统中 flow。UI调用调用 Driver 的执行接口（步骤1）。Driver 为 query 创建 session handle，并将 query 发送到 Compiler 以生成执行计划（步骤2）。Compiler 从 <code>metastore</code> 中获取必要的 <code>metadata</code>（步骤3和4）。该 <code>metadata</code> 用于对查询树中 (query tree) 的表达式进行类型检查，以及基于查询谓词 (query predicates) 修剪 <code>partition</code>。编译器生成的计划（步骤5）是阶段的DAG，每个阶段是一个 Map / Reduce 作业，<code>metadata</code> 操作或对 HDFS 的操作。对于 Map / Reduce阶段，该 plan 包含 Map Operator Trees（在 Mapper 上执行的 Operator Trees）和 Reduce Operator Tree（用于需要 Reducers 的运算）。Execution Engine 将这些 stages 将这些阶段提交给适当的组件（步骤6、6.1、6.2和6.3）。在每个任务（Mapper/ Reducer）中，与 <code>table</code> 或中间输出关联的 deserializer 用于从 HDFS 文件读取行，并将这些行通过关联的 operator tree 传递。生成输出后，将通过 serializer 将其写入临时 HDFS 文件中（如果不需要 Reduce 操作，则在 Napper 发生）。临时文件用于向计划的后续 Map/ Reduce 阶段提供数据。对于 DML 操作，最终的临时文件将移动到 <code>table</code> 的位置。此方案用于确保脏数据 (dirty data) 不会被读取（文件重命名是 HDFS 中的 atomic 操作）。对于查询 (query)，Execution Engine直接从 HDFS 读取临时文件的内容，作为 Driver 进行提取调用的一部分（步骤7、8和9）。</p>
</div>


<style type="text/css">
.content .tabs ul { margin: 0; }
.tab-content { display: none; }
</style>

<script>
function onTabClick (event) {
    var tabTitle = $(event.currentTarget).children('span:last-child').text();
    $('.article .content .tab-content').css('display', 'none');
    $('.article .content .tabs li').removeClass('is-active');
    $('#' + tabTitle).css('display', 'block');
    $(event.currentTarget).parent().addClass('is-active');
}
</script>

<h2 id="Hive-Data-Model"><a href="#Hive-Data-Model" class="headerlink" title="Hive Data Model"></a>Hive Data Model</h2><p>Data in Hive is organized into:</p>
<ul>
<li><strong>Tables</strong> – These are analogous to Tables in Relational Databases. Tables can be filtered, projected, joined and unioned. Additionally all the data of a table is stored in a directory in HDFS. Hive also supports the notion of external tables wherein a table can be created on prexisting files or directories in HDFS by providing the appropriate location to the table creation DDL. The rows in a table are organized into typed columns similar to Relational Databases.</li>
<li><strong>Partitions</strong> – Each Table can have one or more partition keys which determine how the data is stored, for example a table T with a date partition column ds had files with data for a particular date stored in the <code>&lt;table location&gt;/ds=&lt;date&gt;</code> directory in HDFS. Partitions allow the system to prune data to be inspected based on query predicates, for example a query that is interested in rows from T that satisfy the predicate T.ds = ‘2008-09-01’ would only have to look at files in <code>&lt;table location&gt;/ds=2008-09-01/</code> directory in HDFS.</li>
<li><strong>Buckets</strong> – Data in each partition may in turn be divided into Buckets based on the hash of a column in the table. Each bucket is stored as a file in the partition directory. Bucketing allows the system to efficiently evaluate queries that depend on a sample of data (these are queries that use the SAMPLE clause on the table).</li>
</ul>
<p>Apart from primitive column types (integers, floating point numbers, generic strings, dates and booleans), Hive also supports arrays and maps. Additionally, users can compose their own types programmatically from any of the primitives, collections or other user-defined types. The typing system is closely tied to the SerDe (Serailization/Deserialization) and object inspector interfaces. User can create their own types by implementing their own object inspectors, and using these object inspectors they can create their own SerDes to serialize and deserialize their data into HDFS files). These two interfaces provide the necessary hooks to extend the capabilities of Hive when it comes to understanding other data formats and richer types. Builtin object inspectors like ListObjectInspector, StructObjectInspector and MapObjectInspector provide the necessary primitives to compose richer types in an extensible manner. For maps (associative arrays) and arrays useful builtin functions like size and index operators are provided. The dotted notation is used to navigate nested types, for example a.b.c = 1 looks at field c of field b of type a and compares that with 1.</p>
<h1 id="Hive-工作原理"><a href="#Hive-工作原理" class="headerlink" title="Hive 工作原理"></a>Hive 工作原理</h1><ul>
<li>SQL 语句转换成 MapReduce 作业的基本原理</li>
<li>Hive 中 SQL 查询转换成 MapReduce 作业的过程</li>
</ul>
<h2 id="SQL-语句转换成-MapReduce-的基本原理"><a href="#SQL-语句转换成-MapReduce-的基本原理" class="headerlink" title="SQL 语句转换成 MapReduce 的基本原理"></a>SQL 语句转换成 MapReduce 的基本原理</h2><ol>
<li><strong>join 的实现原理</strong></li>
</ol>
<div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch8/join的实现原理.png" alt="join 的实现原理" title="join 的实现原理" style="width: 100%;"/><br></div>

<p>过程与第 7 章 —— <a href="https://zengzhanhang.com/2020/05/28/intro2BigData7/#%E7%94%A8-MapReduce-%E5%AE%9E%E7%8E%B0%E5%85%B3%E7%B3%BB%E7%9A%84%E8%87%AA%E7%84%B6%E8%BF%9E%E6%8E%A5">用 MapReduce 实现关系的自然连接</a>类似，请参见上一章 MapReduce。</p>
<ol start="2">
<li><strong>group by 的实现原理</strong></li>
</ol>
<p>存在一个分组 (Group By) 操作，其功能是把表 Score 的不同片段按照 rank 和 level 的组合值进行合并，计算不同 rank 和 level 的组合值分别有几条记录：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">rank</span>, <span class="keyword">level</span> ,<span class="keyword">count</span>(*) <span class="keyword">as</span> <span class="keyword">value</span> <span class="keyword">from</span> score <span class="keyword">group</span> <span class="keyword">by</span> <span class="keyword">rank</span>, <span class="keyword">level</span></span><br></pre></td></tr></table></figure></p>
<div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch8/groub-by的实现.png" alt="groub by 的实现原理" title="groub by 的实现原理" style="width: 100%;"/><br></div>

<h2 id="Hive-中-SQL-查询转换成-MapReduce-作业的过程"><a href="#Hive-中-SQL-查询转换成-MapReduce-作业的过程" class="headerlink" title="Hive 中 SQL 查询转换成 MapReduce 作业的过程"></a>Hive 中 SQL 查询转换成 MapReduce 作业的过程</h2><p>当用户向Hive输入一段命令或查询时，Hive需要与Hadoop交互工作来完成该操作:</p>
<ul>
<li>驱动模块接收该命令或查询编译器</li>
<li>对该命令或查询进行解析编译</li>
<li>由优化器对该命令或查询进行优化计算</li>
<li>该命令或查询通过执行器进行执行</li>
</ul>
<p><strong>请参见上面 <a href="http://localhost:4000/2020/05/29/intro2BigData8/#Hive-Architecture">Sec 2.1 - Hive Architecture</a> 介绍的图及过程。</strong></p>

<div class="level">
<div class="level-start" style="width: 80%;">
    <img src="/notes/BigData/assets/ch8/hive中sql查询转换成MapReduce作业的过程.png" alt="Hive 中 sql 查询转换成 MapReduce 作业的过程" title="Hive 中 sql 查询转换成 MapReduce 作业的过程" style="width: 100%;"/>
</div>



<div class="level-end" style="width: 100%;">

<ol>
<li>由 Hive 驱动模块中的编译器对用户输入的 SQL 语言进行词法和语法解析，将 SQL 语句转化为抽象语法树的形式</li>
<li>抽象语法树的结构仍很复杂，不方便直接翻译为 MapReduce 算法程序，因此，把抽象语法书转化为查询块</li>
<li>把查询块转换成逻辑查询计划，里面包含了许多逻辑操作符</li>
<li>重写逻辑查询计划，进行优化，合并多余操作，减少 MapReduce 任务数量</li>
<li>将逻辑操作符转换成需要执行的具体 MapReduce 任务</li>
<li>对生成的 MapReduce 任务进行优化，生成最终的 MapReduce 任务执行计划</li>
<li>由 Hive 驱动模块中的执行器，对最终的 MapReduce 任务进行执行输出</li>
</ol>

</div>
</div>

<p><strong>几点说明</strong></p>
<ul>
<li>当启动 MapReduce 程序时，Hive 本身是不会生成 MapReduce 算法程序的</li>
<li>需要通过一个表示 “Job 执行计划” 的 XML 文件驱动执行内置的、原生的 Mapper 和 Reducer 模块</li>
<li>Hive 通过和 JobTracker 通信来初始化 MapReduce 任务，不必直接部署在 JobTracker 所在的管理节点上执行</li>
<li>通常在大型集群上，会有专门的网关机来部署 Hive 工具。网关机的作用主要是远程操作和管理节点上的 JobTracker 通信来执行任务</li>
<li>数据文件通常存储在 HDFS 上，HDFS 由名称节点管理</li>
</ul>
<h1 id="Hive-High-Availability-Hive-HA"><a href="#Hive-High-Availability-Hive-HA" class="headerlink" title="Hive High Availability (Hive HA)"></a>Hive High Availability (Hive HA)</h1><div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch8/HiveHA.png" alt="Hive HA 基本原理" title="Hive HA 基本原理" style="width: 100%;"/><br></div>

<ul>
<li>将若干 Hive 实例纳入一个资源池，并由 HAProxy 提供一个统一的对外接口</li>
<li>对于程序开发人员，就把它认为是一台超强 “hive” 就可以。每次它接收到一个 Hive 查询连接后，都会轮询资源池里可用的 Hive 资源。这样，能充分使用每个 Hive server，减少压力。在拿到 Hive 连接后，Hive HA 会首先进行逻辑可用测试，这个逻辑规则可自行配置。<ul>
<li>如果逻辑可用，则直接把客户端的HIVE 查询连接 relay到该hive server。</li>
<li>若逻辑不可用，则将该hiveserver放入黑名单，然后继续读取池里其他hive server进行连接测试。</li>
</ul>
</li>
<li>Hive HA 每隔一段时间 (可配置)，对黑名单中的 Hive server 进行处理，通过和节点管理服务器通讯，重启该 Hive server。如果重启后可用，则将该 Hive 从黑名单中移除，加入资源池。</li>
</ul>
</div><ul class="post-copyright"><li><strong>Title: </strong><a href="/2020/05/29/intro2BigData8/">大数据技术原理与应用 - (8). Hive - 基于 Hadoop 的数据仓库</a></li><li><strong>Author: </strong><a href="/">Zhanhang (Kyle) ZENG</a></li><li><strong>Link: </strong><a href="/2020/05/29/intro2BigData8/">https://zengzhanhang.com/2020/05/29/intro2BigData8/</a></li><li><strong>Released Date: </strong>2020-05-29</li><li><strong>Last update: </strong>2020-06-01</li><li><strong>Statement: </strong>All articles in this blog, unless otherwise stated, are based on the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> license.</li></ul><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex mb-2"><div class="level-start"><div class="article-tags size-small is-uppercase"><span class="mr-2"><i class="fas fa-tags has-text-grey"></i> #</span><a class="link-muted mr-2" rel="tag" href="/tags/Big-Data/">Big Data</a></div></div><div class="level-start"><div style="text-align:center"></div></div></div><div style="text-align:center"><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=5ebfed406b62a000122baf21&amp;product=inline-share-buttons" defer></script></div></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/img/QRcode/alipay.jpg" alt="Alipay"></span></a><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/img/QRcode/WeChatPay.jpg" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/06/01/intro2BigData9/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">大数据技术原理与应用 - (9). Hadoop 的优化与发展</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/05/28/intro2BigData7/"><span class="level-item">大数据技术原理与应用 - (7). MapReduce</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: '80af703fa03958319d002428b010584d',
            repo: 'zengzhanhang.github.io',
            owner: 'zengzhanhang',
            clientID: '13624a11c95a2d5eed31',
            clientSecret: '67d97a17e7f385cf24a8a24e3bbfaa1e8fcc20c4',
            admin: ["zengzhanhang"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 10,
            pagerDirection: 'last',
            
            
            enableHotKey: true
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="is-rounded" src="/img/icon(square)-min.png" alt="Zhanhang (Kyle) Zeng"></figure><p class="title is-size-4 is-block line-height-inherit">Zhanhang (Kyle) Zeng</p><p class="is-size-6 is-block">Statistics, Machine Learning &amp; Ai</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Edinburgh, Scotland</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">21</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">11</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">17</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded follow-button" href="https://github.com/zengzhanhang" target="_blank" rel="noopener"><i class="fab fa-github"></i>  Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Linkedin" href="https://www.linkedin.com/in/zhanhang-zeng-801a67185/"><i class="fab fa-linkedin-in"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/zengzhanhang"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://www.facebook.com/zengzhanhang"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Instagram" href="https://www.instagram.com/cengzhanhang"><i class="fab fa-instagram"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://www.weibo.com/zengzhanhang"><i class="fab fa-weibo"></i></a></div></div></div><div class="card widget is-sticky" id="toc"><div class="card-content"><div class="menu catalogue-other-setting"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="is-flex" href="#Hive-概述"><span class="mr-2">1</span><span>Hive 概述</span></a><ul class="menu-list"><li><a class="is-flex" href="#数据仓库概念"><span class="mr-2">1.1</span><span>数据仓库概念</span></a></li><li><a class="is-flex" href="#Hive-简介"><span class="mr-2">1.2</span><span>Hive 简介</span></a></li><li><a class="is-flex" href="#Hive-特点"><span class="mr-2">1.3</span><span>Hive 特点</span></a></li><li><a class="is-flex" href="#Hive-和-RDBMS-的对比"><span class="mr-2">1.4</span><span>Hive 和 RDBMS 的对比</span></a></li><li><a class="is-flex" href="#Hive在企业中的部署和应用"><span class="mr-2">1.5</span><span>Hive在企业中的部署和应用</span></a></li></ul></li><li><a class="is-flex" href="#Hive-Design"><span class="mr-2">2</span><span>Hive Design</span></a><ul class="menu-list"><li><a class="is-flex" href="#Hive-Architecture"><span class="mr-2">2.1</span><span>Hive Architecture</span></a></li><li><a class="is-flex" href="#Hive-Data-Model"><span class="mr-2">2.2</span><span>Hive Data Model</span></a></li></ul></li><li><a class="is-flex" href="#Hive-工作原理"><span class="mr-2">3</span><span>Hive 工作原理</span></a><ul class="menu-list"><li><a class="is-flex" href="#SQL-语句转换成-MapReduce-的基本原理"><span class="mr-2">3.1</span><span>SQL 语句转换成 MapReduce 的基本原理</span></a></li><li><a class="is-flex" href="#Hive-中-SQL-查询转换成-MapReduce-作业的过程"><span class="mr-2">3.2</span><span>Hive 中 SQL 查询转换成 MapReduce 作业的过程</span></a></li></ul></li><li><a class="is-flex" href="#Hive-High-Availability-Hive-HA"><span class="mr-2">4</span><span>Hive High Availability (Hive HA)</span></a></li></ul></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img class="logo-img" src="/img/logo_light.png" alt="Zhanhang Zeng&#039;s Blog | 小树的个人博客" height="28"><img class="logo-img-dark" src="/img/logo_dark.png" alt="Zhanhang Zeng&#039;s Blog | 小树的个人博客" height="28"></a><p class="size-small"><span>&copy; 2020 Zhanhang (Kyle) ZENG</span>  All Rights Reserved<br>Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span>    <span id="busuanzi_container_site_pv">Totally, <span id="busuanzi_value_site_pv">0</span> page views</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="fab fa-creative-commons"></i> <i class="fab fa-creative-commons-by"></i> <i class="fab fa-creative-commons-nc"></i> <i class="fab fa-creative-commons-sa"></i> </a><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Zhanhang&#039;s GitHub" href="https://github.com/zengzhanhang"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://zengzhanhang.com',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><script src="/js/main.js" defer></script><script src="/js/imaegoo/universe.js"></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>