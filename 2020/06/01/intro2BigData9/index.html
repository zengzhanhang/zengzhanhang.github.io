<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>大数据技术原理与应用 - (9). Hadoop 的优化与发展 - Zhanhang Zeng&#039;s Blog | 小树的个人博客</title><meta description="【第三篇】 - 大数据处理与分析, 《大数据技术原理与应用, 林子雨》 本篇介绍大数据处理与分析的相关技术，包括  第7章 - MapReduce 第8章 - Hive - 基于 Hadoop 的数据仓库 第9章 - Hadoop 的优化与发展 第10章 - Spark 第11章 - 流计算 第12章 - 图计算  介绍 Hadoop 2.0 对 1.0 不足与局限的解决方案，介绍 Hadoop"><meta property="og:type" content="blog"><meta property="og:title" content="大数据技术原理与应用 - (9). Hadoop 的优化与发展"><meta property="og:url" content="https://zengzhanhang.com/2020/06/01/intro2BigData9/"><meta property="og:site_name" content="Zhanhang Zeng&#039;s Blog | 小树的个人博客"><meta property="og:description" content="【第三篇】 - 大数据处理与分析, 《大数据技术原理与应用, 林子雨》 本篇介绍大数据处理与分析的相关技术，包括  第7章 - MapReduce 第8章 - Hive - 基于 Hadoop 的数据仓库 第9章 - Hadoop 的优化与发展 第10章 - Spark 第11章 - 流计算 第12章 - 图计算  介绍 Hadoop 2.0 对 1.0 不足与局限的解决方案，介绍 Hadoop"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://zengzhanhang.com/notes/BigData/assets/thumbnail.jpg"><meta property="article:published_time" content="2020-06-01T10:42:08.000Z"><meta property="article:modified_time" content="2020-12-29T02:21:24.000Z"><meta property="article:author" content="Zhanhang (Matthew) ZENG"><meta property="article:tag" content="Big Data"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/notes/BigData/assets/thumbnail.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://zengzhanhang.com/2020/06/01/intro2BigData9/"},"headline":"Zhanhang Zeng's Blog | 小树的个人博客","image":["https://zengzhanhang.com/notes/BigData/assets/thumbnail.jpg"],"datePublished":"2020-06-01T10:42:08.000Z","dateModified":"2020-12-29T02:21:24.000Z","author":{"@type":"Person","name":"Zhanhang (Matthew) ZENG"},"description":"【第三篇】 - 大数据处理与分析, 《大数据技术原理与应用, 林子雨》 本篇介绍大数据处理与分析的相关技术，包括  第7章 - MapReduce 第8章 - Hive - 基于 Hadoop 的数据仓库 第9章 - Hadoop 的优化与发展 第10章 - Spark 第11章 - 流计算 第12章 - 图计算  介绍 Hadoop 2.0 对 1.0 不足与局限的解决方案，介绍 Hadoop"}</script><link rel="canonical" href="https://zengzhanhang.com/2020/06/01/intro2BigData9/"><link rel="icon" href="/img/thumbnail.png"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-dark.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?3a6a069adc986db638814c1b4a9e5ce6";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-167464294-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-167464294-1');</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css"><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><script type="text/javascript" src="/js/imaegoo/night.js"></script><canvas id="universe"></canvas><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img class="logo-img" src="/img/logo_light.png" alt="Zhanhang Zeng&#039;s Blog | 小树的个人博客" height="28"><img class="logo-img-dark" src="/img/logo_dark.png" alt="Zhanhang Zeng&#039;s Blog | 小树的个人博客" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/notes_TOC">Notes - 数据科学知识手册</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Zhanhang&#039;s GitHub" href="https://github.com/zengzhanhang"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="thumbnail" src="/notes/BigData/assets/thumbnail.jpg" alt="大数据技术原理与应用 - (9). Hadoop 的优化与发展"></span></div><article class="card-content article" role="article"><h1 class="title is-3 is-size-4-mobile">大数据技术原理与应用 - (9). Hadoop 的优化与发展</h1><div class="article-meta size-small is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time class="level-item" dateTime="2020-06-01T10:42:08.000Z" title="2020-06-01T10:42:08.000Z">2020-06-01</time></span><span class="level-item"><i class="far fa-calendar-check"> </i><time class="level-item" dateTime="2020-12-29T02:21:24.000Z" title="2020-12-29T02:21:24.000Z">Edit: 2020-12-29</time></span><span class="level-item"><i class="fas fa-user"> </i>Zhanhang (Matthew) ZENG</span><span class="level-item"><i class="far fa-clock"></i> 27 minutes read (About 3982 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="busuanzi_value_page_pv">0</span> visits</span></div><div class="level-left is-uppercase mt-2"><span class="level-item"><i class="fas fa-folder-open has-text-grey"></i> <a class="link-muted" href="/categories/Big-Data/">Big Data</a><span> / </span><a class="link-muted" href="/categories/Big-Data/Spark/">Spark</a></span><span class="level-item"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/Big-Data/">Big Data</a></span></div></div><div class="content"><div class="notification is-warning">
<p><strong>【第三篇】 - 大数据处理与分析</strong>, 《大数据技术原理与应用, 林子雨》</p>
<p>本篇介绍大数据处理与分析的相关技术，包括</p>
<ul>
<li>第7章 - <a href="#">MapReduce</a></li>
<li>第8章 - <a href="#">Hive - 基于 Hadoop 的数据仓库</a></li>
<li>第9章 - <a href="#"><strong>Hadoop 的优化与发展</strong></a></li>
<li>第10章 - <a href="#">Spark</a></li>
<li>第11章 - <a href="#">流计算</a></li>
<li>第12章 - <a href="#">图计算</a></li>
</ul>
<p>介绍 Hadoop 2.0 对 1.0 不足与局限的解决方案，介绍 Hadoop 2.0 的新特性以及新一代资源管理调度框架 YARN 框架。</p>
</div>
<a id="more"></a>
<h1 id="Hadoop-局限与改进"><a href="#Hadoop-局限与改进" class="headerlink" title="Hadoop 局限与改进"></a>Hadoop 局限与改进</h1><h2 id="Hadoop-的局限与不足"><a href="#Hadoop-的局限与不足" class="headerlink" title="Hadoop 的局限与不足"></a>Hadoop 的局限与不足</h2><p>Hadoop 1.0 的核心组件 (仅指 MapReduce 和 HDFS，不包括 Hadoop 生态系统内的 Pig、Hive、HBase 等其他组件)，主要存在以下不足：</p>
<ul>
<li><strong>抽象层次低</strong>。有时候为了实现一个简单的功能，也需要编写大量的代码。</li>
<li><strong>表达能力有限</strong>。MapReduce 把复杂的分布式编程工作高度抽象到两个函数上，即 Map 和 Reduce，但是实际生产环境中的一些应用是无法用简单的 Map 和 Reduce 来完成。</li>
<li><strong>开发者自己管理作业（Job）之间的依赖关系</strong>。一个 Job 只包含 Map 和 Reduce 两个阶段，通常的实际应用问题需要大量的 job 进行协作才能顺利解决，这些 job 之间往往存在复杂的依赖关系，但是 MapReduce 框架本身并没有提供相关的机制对这些依赖关系进行有效管理。</li>
<li><strong>难以看到程序整体逻辑</strong>。</li>
<li><strong>执行迭代操作效率低</strong>。对于一些机器学习、数据挖掘任务，往往需要多轮迭代才能得到结果，如遗传算法。但是 Map、Reduce 的过程需要对 HDFS 的数据进行读写，反复读写 HDFS 文件中的数据，大大降低了迭代操作的效率。</li>
<li><strong>资源浪费（Map和Reduce分两阶段执行）</strong>。MapReduce 的框架设计中，Reduce 任务需要等待所有 Map 任务都完成才可以开始，造成了不必要的资源浪费。</li>
<li><strong>实时性差（适合批处理，不支持实时交互式）</strong>。</li>
</ul>
<p><strong>两方面改进</strong></p>
<ul>
<li>一方面是 Hadoop 自身两大核心组件 MapReduce 和 HDFS 的架构设计改进</li>
<li>另一方面是 Hadoop 生态系统其它组件的不断丰富，加入了 Pig、Tez、Spark 和 Kafka 等新组件</li>
</ul>
<div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch9/Hadoop优化.png" alt="Hadoop 1.0 到 2.0" title="Hadoop 1.0 到 2.0" style="width: 70%;"/><br></div>

<h2 id="改进-Hadoop-框架"><a href="#改进-Hadoop-框架" class="headerlink" title="改进 Hadoop 框架"></a>改进 Hadoop 框架</h2><div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch9/Hadoop框架自身的改进.png" alt="Hadoop 框架自身的改进: 从1.0到2.0" title="Hadoop 框架自身的改进: 从1.0到2.0" style="width: 70%;"/><br></div>

<h2 id="完善-Hadoop-生态"><a href="#完善-Hadoop-生态" class="headerlink" title="完善 Hadoop 生态"></a>完善 Hadoop 生态</h2><table>
<thead>
<tr>
<th style="text-align:center"><div style="text-align:center; width:80px">组件</div></th>
<th><div style="text-align:center">功能</div></th>
<th><div style="text-align:center">解决 Hadoop 中存在的问题</div></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Pig</td>
<td>处理大规模数据的脚本语言，用户只需要编写几条简单的语句，系统会自动转换为MapReduce作业</td>
<td>抽象层次低，需要手工编写大量代码</td>
</tr>
<tr>
<td style="text-align:center">Spark</td>
<td>基于内存的分布式并行编程框架，具有较高的实时性，并且较好支持迭代计算</td>
<td>延迟高，而且不适合执行迭代计算</td>
</tr>
<tr>
<td style="text-align:center">Oozie</td>
<td>工作流和协作服务引擎，协调Hadoop上运行的不同任务</td>
<td>没有提供作业（Job）之间依赖关系管理机制，需要用户自己处理作业之间依赖关系</td>
</tr>
<tr>
<td style="text-align:center">Tez</td>
<td>支持DAG作业的计算框架，对作业的操作进行重新分解和组合，形成一个大的DAG作业，减少不必要操作</td>
<td>不同的MapReduce任务之间存在重复操作，降低了效率</td>
</tr>
<tr>
<td style="text-align:center">Kafka</td>
<td>分布式发布订阅消息系统，一般作为企业大数据分析平台的数据交换枢纽，不同类型的分布式系统可以统一接入到Kafka，实现和Hadoop各个组件之间的不同类型数据的实时高效交换</td>
<td>Hadoop生态系统中各个组件和其他产品之间缺乏统一的、高效的数据交换中介</td>
</tr>
</tbody>
</table>
<h1 id="HDFS2-0-的新特性"><a href="#HDFS2-0-的新特性" class="headerlink" title="HDFS2.0 的新特性"></a>HDFS2.0 的新特性</h1><h2 id="HDFS-HA"><a href="#HDFS-HA" class="headerlink" title="HDFS HA"></a>HDFS HA</h2><p><strong>HDFS 1.0 的不足</strong></p>
<ul>
<li>HDFS 1.0 只存在一个 NameNode，存在单点故障问题。</li>
<li>第二名称节点 (SecondaryNameNode) 无法解决单点故障问题，非 NameNode 的热备份。</li>
</ul>
<p><strong>HDFS HA（High Availability）是为了解决单点故障问题</strong>，是 NameNode 的热备份解决方案。</p>
<ul>
<li>HA 集群设置两个 NameNode，“<strong>活跃</strong> (Active)”和“<strong>待命</strong> (Standby)”。</li>
<li>两种 NameNode 的状态同步，可以借助于一个共享存储系统来实现。</li>
<li><strong>一旦活跃 NameNode 出现故障，就可以立即切换到待命 NameNode。</strong></li>
<li>Zookeeper 确保只有一个 NameNode 在对外服务。</li>
<li>NameNode 维护映射信息，数据节点同时向两个 NameNode 汇报信息。</li>
</ul>
<div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch9/HDFS_HA框架.png" alt="Hadoop HA 框架" title="Hadoop HA 框架" style="width: 100%;"/><br></div>

<h2 id="HDFS-Federation"><a href="#HDFS-Federation" class="headerlink" title="HDFS Federation"></a>HDFS Federation</h2><p><strong>HDFS 1.0 的不足</strong></p>
<ul>
<li>单点故障问题</li>
<li>不可以水平扩展（是否可以通过纵向扩展来解决？）</li>
<li>系统整体性能受限于单个 NameNode 的吞吐量</li>
<li>单个 NameNode 难以提供不同程序之间的隔离性</li>
<li>HDFS HA 是热备份，提供高可用性，但是无法解决可扩展性、系统性能和隔离性</li>
</ul>
<p><strong>HDFS Federation 的设计</strong></p>
<ul>
<li>在 HDFS Federation 中，设计了多个<strong>相互独立</strong>的 NameNode，使得 HDFS 的命名服务能够水平扩展，这些 NameNode 分别进行各自命名空间和块的管理，相互之间是联盟 (Federation) 关系，不需要彼此协调。并且向后兼容。</li>
<li>HDFS Federation 中，所有 NameNode 会共享底层的 DataNode 存储资源，DataNode 向所有 NameNode 汇报。</li>
<li>属于同一个命名空间的块构成一个 “块池”。</li>
</ul>
<div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch9/HDFS_Federation框架.png" alt="Hadoop Federation 框架" title="Hadoop Federation 框架" style="width: 100%;"/><br></div>

<p><strong>HDFS Federation 的访问方式</strong></p>
<ul>
<li>对于 Federation 中的多个命名空间，可以采用客户端挂载表 （lient SideMount Table) 方式进行数据共享和访问。</li>
<li>客户可以访问不同的挂载点来访问不同的子命名空间</li>
<li>把各个命名空间挂载到全局 “挂载表” (mount-table) 中，实现数据全局共享</li>
<li>同样的命名空间挂载到个人的挂载表中，就成为应用程序可见的命名空间</li>
</ul>
<p><strong>HDFS Federation 相对于 HDFS1.0 的优势</strong></p>
<ol>
<li><strong>HDFS集群扩展性</strong>。多个 NameNode 各自分管一部分目录，使得一个集群可以扩展到更多节点，不再像 HDFS1.0 中那样由于内存的限制制约文件存储数目。</li>
<li><strong>性能更高效</strong>。多个 NameNode 管理不同的数据，且同时对外提供服务，将为用户提供更高的读写吞吐率。</li>
<li><strong>良好的隔离性</strong>。用户可根据需要将不同业务数据交由不同 NameNode 管理，这样不同业务之间影响很小。</li>
</ol>
<p>需要注意: HDFS Federation 并不能解决单点故障问题，也就是说，每个 NameNode 都存在在单点故障问题，需要为每个 NameNode 部署一个后备 NameNode，以应对 NameNode 挂掉对业务产生的影响。</p>
<h2 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h2><p><strong>MapReduce1.0 的缺陷</strong></p>
<ol>
<li>存在单点故障</li>
<li>JobTracker “大包大揽”导致任务过重 (任务多时内存开销大，上限4000节点)</li>
<li>容易出现内存溢出 (分配资源只考虑 MapReduce 任务数，不考虑 CPU、内存)</li>
<li>资源划分不合理 (强制划分为 slot ，包括 Map slot 和 Reduce slot)</li>
</ol>
<div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch9/MapReduce1体系.png" alt="MapReduce1.0 体系结构" title="MapReduce1.0 体系结构" style="width: 100%;"/><br></div>

<p><strong>YARN 设计思路</strong></p>
<ul>
<li>MapReduce1.0 既是一个计算框架，也是一个资源管理调度框架</li>
<li>到了 Hadoop2.0 以后，<strong>MapReduce1.0 中的资源管理调度功能，被单独分离出来形成了 YARN</strong>，它是一个纯粹的资源管理调度框架，而不是一个计算框架</li>
<li><strong>被剥离了资源管理调度功能的 MapReduce 框架就变成了 MapReduce2.0</strong>，它是运行在 YARN 之上的一个纯粹的计算框架，不再自己负责资源调度管理服务，而是由 YARN 为其提供资源管理调度服务</li>
</ul>
<p><strong>YARN 体系结构</strong></p>
<div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch9/YARN架构思路.png" alt="YARN 架构思路: 将原 JobTacker 三大功能拆分" title="YARN 架构思路: 将原 JobTacker 三大功能拆分" style="width: 75%;"/><br></div>

<ul>
<li>ResourceManager:<ul>
<li>处理客户端请求</li>
<li>启动/监控 ApplicationMaster</li>
<li>监控 NodeManager</li>
<li>资源分配与调度</li>
</ul>
</li>
<li>ApplicationMaster:<ul>
<li>为应用程序申请资源，并分配给内部任务</li>
<li>任务调度、监控与容错</li>
</ul>
</li>
<li>NodeManager:<ul>
<li>单个节点上的资源管理</li>
<li>处理来自 ResourceManger 的命令</li>
<li>处理来自 ApplicationMaster 的命令</li>
</ul>
</li>
</ul>
<p><strong>YARN 工作流程</strong></p>
<div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch9/YARN工作流程.png" alt="YARN 架构思路: 将原 JobTacker 三大功能拆分" title="YARN 架构思路: 将原 JobTacker 三大功能拆分" style="width: 75%;"/><br></div>

<ol>
<li>用户编写客户端 (Clinet) 应用程序，向 YARN 提交应用程序，提交的内容包括 ApplicationMaster 程序、启动 ApplicationMaster 的命令、用户程序等</li>
<li>YARN 中的 ResourceManager 负责接收和处理来自 Clinet 的请求，为应用程序分配一个容器，在该容器中启动一个 ApplicationMaster</li>
<li>ApplicationMaster 被创建后会首先向 ResourceManager 注册</li>
<li>ApplicationMaster 采用<strong>轮询</strong>的方式向 ResourceManager 申请资源</li>
<li>ResourceManager 以“容器”的形式向提出申请的 ApplicationMaster 分配资源</li>
<li>在容器中启动任务（运行环境、脚本）</li>
<li>各个任务向 ApplicationMaster 汇报自己的状态和进度</li>
<li>应用程序运行完成后，ApplicationMaster 向 ResourceManager 的应用程序管理器注销并关闭自己</li>
</ol>
<h1 id="Hadoop-生态中代表性功能组件"><a href="#Hadoop-生态中代表性功能组件" class="headerlink" title="Hadoop 生态中代表性功能组件"></a>Hadoop 生态中代表性功能组件</h1><h2 id="Pig"><a href="#Pig" class="headerlink" title="Pig"></a>Pig</h2><p><strong>Pig 是什么</strong></p>
<p>Pig 是一个基于 Apache Hadoop 的大规模 High-Level 数据分析平台。Pig 可以 在MapReduce，Apache Tez 或 Apache Spark 中执行其 Hadoop 作业，它提供的 SQL-LIKE 语言 - <strong>Pig Latin</strong>，该语言的编译器会把类 SQL 的数据分析请求转换为一系列经过优化处理的 MapReduce 运算。Pig 为复杂的海量数据并行计算提供了一个简单的操作和编程接口，Pig Latin 可以使用 user-defined functions (UDF) 进行扩展，用户可以使用 Java，Python，JavaScript，Ruby 或 Groovy 编写这些函数，然后直接从该语言调用。</p>
<p>Pig 可以加载数据、表达转换数据以及存储最终结果。</p>
<p><strong>Pig Latin</strong></p>
<p>Pig Latin是这样的一个操作：通过<strong>对关系进行处理产生另外一组关系</strong>。Pig Latin语言在书写一条语句的时候能够<strong>跨越多行</strong>，但是必须以<strong>半角的分号</strong>来结束。</p>
<p>Pig Latin语言通常按照下面的流程来编写：</p>
<ol>
<li>通过一条 <strong>LOAD语句</strong> 从文件系统中读取数据；</li>
<li>通过一系列 <strong>转换语句</strong> 对数据进行处理；</li>
<li>通过一条 <strong>STORE语句</strong> 把处理结果输出到文件系统中，或者使用一条DUMP语句把处理结果输出在屏幕上。</li>
</ol>
<p>LOAD和STORE语句有严格的语法规定，用户很容易就能掌握，关键是如何灵活的使用转换语句对数据进行处理。</p>
<p><strong>Pig Latin 例子</strong></p>
<figure class="highlight pgsql"><figcaption><span>example</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">input_lines = <span class="keyword">LOAD</span> <span class="string">'/tmp/my-copy-of-all-pages-on-internet'</span> <span class="keyword">AS</span> (<span class="type">line</span>:chararray);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- Extract words from each line and put them into a pig bag</span></span><br><span class="line"><span class="comment">-- datatype, then flatten the bag to get one word on each row</span></span><br><span class="line">words = <span class="keyword">FOREACH</span> input_lines GENERATE FLATTEN(TOKENIZE(<span class="type">line</span>)) <span class="keyword">AS</span> word;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- filter out any words that are just white spaces</span></span><br><span class="line">filtered_words = <span class="keyword">FILTER</span> words <span class="keyword">BY</span> word MATCHES <span class="string">'\\w+'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- create a group for each word</span></span><br><span class="line">word_groups = <span class="keyword">GROUP</span> filtered_words <span class="keyword">BY</span> word;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- count the entries in each group</span></span><br><span class="line">word_count = <span class="keyword">FOREACH</span> word_groups GENERATE COUNT(filtered_words) <span class="keyword">AS</span> count, <span class="keyword">group</span> <span class="keyword">AS</span> word;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- order the records by count</span></span><br><span class="line">ordered_word_count = <span class="keyword">ORDER</span> word_count <span class="keyword">BY</span> count <span class="keyword">DESC</span>;</span><br><span class="line">STORE ordered_word_count <span class="keyword">INTO</span> <span class="string">'/tmp/number-of-words-on-internet'</span>;</span><br></pre></td></tr></table></figure>
<p>上面的程序将生成并行的可执行任务，这些任务可以分布在 Hadoop 集群中的多台计算机上，以计算数据集（例如互联网上的所有网页）中的单词数。</p>
<h2 id="Tez"><a href="#Tez" class="headerlink" title="Tez"></a>Tez</h2><p>Tez 是 Apache 开源的<strong>支持 DAG作业</strong>的计算框架，它直接源于 MapReduce 框架，核心思想是将 Map 和 Reduce 两个操作进一步拆分。</p>
<ul>
<li>Map 被拆分成 Input、Processor、Sort、Merge 和 Output</li>
<li>Reduce 被拆分成 Input、Shuffle、Sort、Merge、Processor 和 Output 等</li>
</ul>
<p>分解后的元操作可以任意灵活组合，产生新的操作，这些操作经过一些控制程序组装后，可形成一个大的 DAG 作业。通过 DAG 作业的方式运行 MapReduce 作业，提供了程序运行的整体处理逻辑，就可以去除工作流当中多余的 Map 阶段，减少不必要的操作，提升数据处理的性能。</p>
<p><strong>MapReduce 和 Tez 对比</strong></p>
<p>Tez的优化主要体现在，去除了</p>
<ul>
<li>连续两个作业之间的 <strong>“写入HDFS”</strong></li>
<li>每个工作流中<strong>多余的 Map 阶段</strong></li>
</ul>
<p>比如以下 Hive SQL 会翻译成四个MR作业，而采用 Tez 则生成一个 DAG 作业，可大大减少磁盘 IO：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a.state, <span class="keyword">COUNT</span>(*),AVERAGE(c.price)</span><br><span class="line"><span class="keyword">FROM</span> a</span><br><span class="line"><span class="keyword">JOIN</span> b <span class="keyword">ON</span> (a.id = b.id)</span><br><span class="line"><span class="keyword">JOIN</span> c <span class="keyword">ON</span> (a.itemId = c.itemId)</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> a.state</span><br></pre></td></tr></table></figure>
<div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch9/HiveQL和Tez对比.png" alt="HiveQL 语句在 MapReduce 和 Tez 中的执行情况对比" title="HiveQL 语句在 MapReduce 和 Tez 中的执行情况对比" style="width: 100%;"/><br></div>

<p><strong>Tez 作用</strong></p>
<ul>
<li>在 Hadoop2.0 生态系统中 (参考上图: <a href="#Hadoop-的局限与不足">Hadoop 1.0 到 2.0</a>)，MapReduce、Hive、Pig 等计算框架，都需要最终以 MapReduce 任务的形式执行数据分析，因此 Tez 框架可以发挥重要的作用</li>
<li>借助于 Tez 框架实现对 MapReduce、Pig 和 Hive 等的性能优化</li>
<li>可以解决现有 MapReduce 框架在迭代计算 (如 PageRank algorithms) 和交互式计算方面的问题</li>
</ul>
<p><strong>(Tez+Hive) 与 Impala、Dremel 和 Drill 的区别？</strong></p>
<ul>
<li>Tez 在解决 Hive、Pig 延迟大、性能低等问题的思路，是和那些支持实时交互式查询分析的产品（如 Impala、Dremel 和 Drill 等）是不同的。</li>
<li>Impala、Dremel 和 Drill 的解决问题思路是抛弃 MapReduce 计算框架，不再将类似 SQL 语句的 HiveQL 或者 Pig 语句翻译成 MapReduce 程序，而是采用与商用并行关系数据库类似的分布式查询引擎，可以直接从 HDFS 或者 HBase 中用 SQL 语句查询数据，而不需要把 SQL 语句转化成 MapReduce 任务来执行，从而大大降低了延迟，很好地满足了实时查询的要求。</li>
<li>Tez 则不同，比如，针对 Hive 数据仓库进行优化的 “Tez+Hive” 解决方案，仍采用 MapReduce 计算框架，但是对 DAG 的作业依赖关系进行了裁剪，并将多个小作业合并成一个大作业，这样，不仅计算量减少了，而且写HDFS次数也会大大减少。</li>
</ul>
<h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><p>Hadoop 缺陷: 其 MapReduce 计算模型<strong>延迟过高</strong>，无法胜任实时、快速计算的需求，因而只适用于离线批处理的应用场景</p>
<ul>
<li>中间结果写入磁盘，每次运行都从磁盘读数据</li>
<li>在前一个任务执行完成之前，其他任务无法开始，难以胜任复杂、多阶段的计算任务</li>
</ul>
<p>Spark 最初诞生于伯克利大学的 APM 实验室，是一个可应用于大规模数据处理的快速、通用引擎，如今是 Apache 软件基金会下的顶级开源项目之一。Spark 在借鉴Hadoop MapReduce 优点的同时，很好地解决了 MapReduce 所面临的问题:</p>
<ul>
<li>内存计算，带来了更高的迭代运算效率</li>
<li>基于 DAG 的任务调度执行机制，优于 MapReduce 的迭代执行机制</li>
</ul>
<p>详见下一章 - 第10章: Spark 内容。</p>
<h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><ul>
<li>Kafka 是一种<strong>高吞吐量的分布式发布订阅消息系统</strong>，用户通过 Kafka 系统可以发布大量的消息，同时也能实时订阅消费消息</li>
<li>Kafka 可以同时满足<strong>在线实时处理</strong>和<strong>批量离线处理</strong></li>
<li>在公司的大数据生态系统中，可以把 Kafka 作为<strong>数据交换枢纽</strong>，不同类型的分布式系统（关系数据库、NoSQL 数据库、流处理系统、批处理系统等），可以统一接入到Kafka，<strong>实现和 Hadoop 各个组件之间的不同类型数据的实时高效交换</strong></li>
</ul>
<div style="text-align:center"><br>    <img src="/notes/BigData/assets/ch9/kafka作为数据交换枢纽.png" alt="Kafka 作为数据交换枢纽" title="Kafka 作为数据交换枢纽" style="width: 100%;"/><br></div>

</div><ul class="post-copyright"><li><strong>Title: </strong><a href="/2020/06/01/intro2BigData9/">大数据技术原理与应用 - (9). Hadoop 的优化与发展</a></li><li><strong>Author: </strong><a href="/">Zhanhang (Matthew) ZENG</a></li><li><strong>Link: </strong><a href="/2020/06/01/intro2BigData9/">https://zengzhanhang.com/2020/06/01/intro2BigData9/</a></li><li><strong>Released Date: </strong>2020-06-01</li><li><strong>Last update: </strong>2020-12-29</li><li><strong>Statement: </strong>All articles in this blog, unless otherwise stated, are based on the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> license.</li></ul><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex mb-2"><div class="level-start"><div class="article-tags size-small is-uppercase"><span class="mr-2"><i class="fas fa-tags has-text-grey"></i> #</span><a class="link-muted mr-2" rel="tag" href="/tags/Big-Data/">Big Data</a></div></div><div class="level-start"><div style="text-align:center"></div></div></div><div style="text-align:center"><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=5ebfed406b62a000122baf21&amp;product=inline-share-buttons" defer></script></div></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/img/QRcode/alipay.jpg" alt="Alipay"></span></a><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/img/QRcode/WeChatPay.jpg" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/06/03/intro2BigData10/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">大数据技术原理与应用 - (10). Spark</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/05/29/intro2BigData8/"><span class="level-item">大数据技术原理与应用 - (8). Hive - 基于 Hadoop 的数据仓库</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: 'd2bcb56bed839c05e3a866764ad12aa8',
            repo: 'zengzhanhang.github.io',
            owner: 'zengzhanhang',
            clientID: '13624a11c95a2d5eed31',
            clientSecret: '67d97a17e7f385cf24a8a24e3bbfaa1e8fcc20c4',
            admin: ["zengzhanhang"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 10,
            pagerDirection: 'last',
            
            
            enableHotKey: true
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="is-rounded" src="/img/icon(square)-min.png" alt="Zhanhang (Matthew) ZENG"></figure><p class="title is-size-4 is-block line-height-inherit">Zhanhang (Matthew) ZENG</p><p class="is-size-6 is-block">Statistics, Machine Learning &amp; Ai</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Edinburgh, Scotland</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">23</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">12</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">18</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded follow-button" href="https://github.com/zengzhanhang" target="_blank" rel="noopener"><i class="fab fa-github"></i>  Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Linkedin" href="https://www.linkedin.com/in/zhanhang-zeng-801a67185/"><i class="fab fa-linkedin-in"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/zengzhanhang"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://www.facebook.com/zengzhanhang"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Instagram" href="https://www.instagram.com/cengzhanhang"><i class="fab fa-instagram"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://www.weibo.com/zengzhanhang"><i class="fab fa-weibo"></i></a></div></div></div><div class="card widget is-sticky" id="toc"><div class="card-content"><div class="menu catalogue-other-setting"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="is-flex" href="#Hadoop-局限与改进"><span class="mr-2">1</span><span>Hadoop 局限与改进</span></a><ul class="menu-list"><li><a class="is-flex" href="#Hadoop-的局限与不足"><span class="mr-2">1.1</span><span>Hadoop 的局限与不足</span></a></li><li><a class="is-flex" href="#改进-Hadoop-框架"><span class="mr-2">1.2</span><span>改进 Hadoop 框架</span></a></li><li><a class="is-flex" href="#完善-Hadoop-生态"><span class="mr-2">1.3</span><span>完善 Hadoop 生态</span></a></li></ul></li><li><a class="is-flex" href="#HDFS2-0-的新特性"><span class="mr-2">2</span><span>HDFS2.0 的新特性</span></a><ul class="menu-list"><li><a class="is-flex" href="#HDFS-HA"><span class="mr-2">2.1</span><span>HDFS HA</span></a></li><li><a class="is-flex" href="#HDFS-Federation"><span class="mr-2">2.2</span><span>HDFS Federation</span></a></li><li><a class="is-flex" href="#YARN"><span class="mr-2">2.3</span><span>YARN</span></a></li></ul></li><li><a class="is-flex" href="#Hadoop-生态中代表性功能组件"><span class="mr-2">3</span><span>Hadoop 生态中代表性功能组件</span></a><ul class="menu-list"><li><a class="is-flex" href="#Pig"><span class="mr-2">3.1</span><span>Pig</span></a></li><li><a class="is-flex" href="#Tez"><span class="mr-2">3.2</span><span>Tez</span></a></li><li><a class="is-flex" href="#Spark"><span class="mr-2">3.3</span><span>Spark</span></a></li><li><a class="is-flex" href="#Kafka"><span class="mr-2">3.4</span><span>Kafka</span></a></li></ul></li></ul></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img class="logo-img" src="/img/logo_light.png" alt="Zhanhang Zeng&#039;s Blog | 小树的个人博客" height="28"><img class="logo-img-dark" src="/img/logo_dark.png" alt="Zhanhang Zeng&#039;s Blog | 小树的个人博客" height="28"></a><p class="size-small"><span>&copy; 2020 Zhanhang (Matthew) ZENG</span>  All Rights Reserved<br>Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span>    <span id="busuanzi_container_site_pv">Totally, <span id="busuanzi_value_site_pv">0</span> page views</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="fab fa-creative-commons"></i> <i class="fab fa-creative-commons-by"></i> <i class="fab fa-creative-commons-nc"></i> <i class="fab fa-creative-commons-sa"></i> </a><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Zhanhang&#039;s GitHub" href="https://github.com/zengzhanhang"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://zengzhanhang.com',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><script src="/js/main.js" defer></script><script src="/js/imaegoo/universe.js"></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>