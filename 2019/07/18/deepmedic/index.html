<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>DeepMedic - multi-sacle 3D CNN with CRF for brain lesion segmentation - 小树的面包店 | ZhanhangZeng&#039;s Blog</title><meta description="论文阅读笔记，如果我有什么理解错误的地方，欢迎大家指正。论文：Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation"><meta property="og:type" content="blog"><meta property="og:title" content="DeepMedic - multi-sacle 3D CNN with CRF for brain lesion segmentation"><meta property="og:url" content="https://zengzhanhang.github.io/2019/07/18/deepmedic/"><meta property="og:site_name" content="小树的面包店 | ZhanhangZeng&#039;s Blog"><meta property="og:description" content="论文阅读笔记，如果我有什么理解错误的地方，欢迎大家指正。论文：Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://ars.els-cdn.com/content/image/1-s2.0-S1361841516301839-gr5_lrg.jpg"><meta property="article:published_time" content="2019-07-18T10:38:56.000Z"><meta property="article:modified_time" content="2020-05-16T13:21:14.179Z"><meta property="article:author" content="Zhanhang ZENG (展航)"><meta property="article:tag" content="CV"><meta property="article:tag" content="Image Segmentation"><meta property="article:tag" content="Medical Imaging"><meta property="article:tag" content="Reading Note"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://ars.els-cdn.com/content/image/1-s2.0-S1361841516301839-gr5_lrg.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://zengzhanhang.github.io/2019/07/18/deepmedic/"},"headline":"小树的面包店 | ZhanhangZeng's Blog","image":["https://ars.els-cdn.com/content/image/1-s2.0-S1361841516301839-gr5_lrg.jpg"],"datePublished":"2019-07-18T10:38:56.000Z","dateModified":"2020-05-16T13:21:14.179Z","author":{"@type":"Person","name":"Zhanhang ZENG (展航)"},"description":"论文阅读笔记，如果我有什么理解错误的地方，欢迎大家指正。论文：Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation"}</script><link rel="canonical" href="https://zengzhanhang.github.io/2019/07/18/deepmedic/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css"><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo1.png" alt="小树的面包店 | ZhanhangZeng&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/notes_TOC">Notes - 数据科学知识手册</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Zhanhang&#039;s GitHub" href="https://github.com/zengzhanhang"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="thumbnail" src="https://ars.els-cdn.com/content/image/1-s2.0-S1361841516301839-gr5_lrg.jpg" alt="DeepMedic - multi-sacle 3D CNN with CRF for brain lesion segmentation"></span></div><article class="card-content article" role="article"><h1 class="title is-3 is-size-4-mobile">DeepMedic - multi-sacle 3D CNN with CRF for brain lesion segmentation</h1><div class="article-meta size-small is-mobile"><div class="level-left"><i class="far fa-calendar-alt"> Post: </i><time class="level-item" dateTime="2019-07-18T10:38:56.000Z" title="2019-07-18T10:38:56.000Z">2019-07-18</time><i class="far fa-calendar-check"> Edit: </i><time class="level-item" dateTime="2020-05-16T13:21:14.179Z" title="2020-05-16T13:21:14.179Z">Edit: 2020-05-16</time><span class="level-item"><i class="far fa-clock"></i> 15 minutes read (About 2308 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="busuanzi_value_page_pv">0</span> visits</span></div><div class="level-left is-uppercase mt-2"><span class="level-item"><i class="fas fa-folder-open has-text-grey"></i> <a class="link-muted" href="/categories/Computer-Vision/">Computer Vision</a><span> / </span><a class="link-muted" href="/categories/Computer-Vision/Networks-Architecture/">Networks Architecture</a></span><span class="level-item"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted mr-2" rel="tag" href="/tags/CV/">CV</a><a class="link-muted mr-2" rel="tag" href="/tags/Image-Segmentation/">Image Segmentation</a><a class="link-muted mr-2" rel="tag" href="/tags/Medical-Imaging/">Medical Imaging</a><a class="link-muted mr-2" rel="tag" href="/tags/Reading-Note/">Reading Note</a></span></div></div><div class="content"><blockquote>
<p>论文阅读笔记，如果我有什么理解错误的地方，欢迎大家指正。<br>论文：<a href="https://www.sciencedirect.com/science/article/pii/S1361841516301839">Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation</a></p>
</blockquote>
<a id="more"></a>
<blockquote>
<p>摘要：作者提出一种双路径，11层深的3D卷积神经网络用于brain lesion segmentation任务，主要解决了医学图像处理上的三个方面的问题。一是作者设计了一种dense training scheme的方案，采用全卷积神经网络，一次把相邻像素的image segments传入网络输出dense prediction (dense-inference)，从而节省了计算代价。作者使用更深的网络使模型判别能力更强。作者使用一种dual pathway architecture，即同时训练两个网络，使模型同时对高/低分辨率图像进行处理。最后作者采用全连接条件随机场(Fully connected Conditional Random Field)对网络output进行后处理(post-processing)改善图像类之间的边缘信息。</p>
</blockquote>
<h1 id="1-Dense-Training"><a href="#1-Dense-Training" class="headerlink" title="1. Dense Training"></a>1. Dense Training</h1><p>在传统patch-wise的分类中，输入patch的尺寸和cnn最后一层神经元的感受野大小相同，这样网络得到一个single prediction对应输入patch的中心像素的值。而用全卷积实现的神经网络，因为其输入的patch的尺寸可以大于最后一层神经元的感受野，因此模型可以同时输出多个prediction，即dense-inference，而每一个prediction对应cnn’s receptive field的在输入patch上的每一步stride。<br><br/><br/></p>
<p><img src="https://ars.els-cdn.com/content/image/1-s2.0-S1361841516301839-gr2_lrg.jpg" alt="Fig.2. Our baseline CNN consists of four layers with $5^3$ kernels for feature extraction, leading to a receptive field of size $17^3$. The classification layer is implemented as convolutional with $1^3$ kernels, which enables efficient dense-inference. When the network segments an input it predicts multiple voxels simultaneously, one for each shift of its receptive field over the input. Number of FMs and their size depicted as (Number × Size)."></p>
<p>同时作者认为，这样dense-inference得到的每一个prediction都是可信的，只要感受野是完全在input patch上扫过，并且只捕捉到原始信息，因此没有使用padding。</p>
<p>Dense Training Scheme 的优点</p>
<ul>
<li>节省计算代价和内存消耗</li>
<li>灵活：作者提到最佳的性能为将整个图像送入网络，但是这个做法不现实。如果GPU内存限制不允许，例如在需要缓存大量FM的大型3D网络的情况下，则将图像分成多个image-segments，这样会比单个segment大，但是可以去fit内存。（原文：If GPU memory constraints do not allow it, such as in the case of large 3D networks where a large number of FMs need to be cached, the volume is tiled in multiple image-segments, which are larger than individual patches, but small enough to fit into memory.）</li>
</ul>
<p>CNNs are trained patch-by-patch: 个人认为论文中提到的这个操作是在图像上randomly crop出一个individual patch作为网络的输入来训练网络，以此计算loss和进行gradient descent。</p>
<h1 id="2-Class-Balance"><a href="#2-Class-Balance" class="headerlink" title="2. Class Balance"></a>2. Class Balance</h1><p>(这里不太确定自己理解对不对)</p>
<p>在原文的Section 2.2中作者提到，这种dense training scheme的方案中的sampling input segments (即上面提到的randomly crop individual patches) 提供了一种灵活的方式去平衡training samples中的segmentation classes（正负类）的分布，而不同的分布对模型的性能有很大的影响。</p>
<p><img src="/Documents/deepmedic/fig_3.png" alt="Fig.3. Consider a network with a 2D receptive field of $3^2$ (for illustration) densely-applied on the depicted lesion-centred image segments of size $7^2$ or $9^2$. Relatively more background (green) is captured by larger segments and around smaller lesions. (For interpretation of the references to colour, the reader is referred to the web version of this article.)"></p>
<p>从上图和原文Section 3.2的实验结果来看，感觉有点类似过采样的意思。上图说明，如果是crop一个以病变为中心 (lesion-centered) 的image segments，分别用 $7 \times 7$ 和 $9 \times 9$ 的框去crop下来，可以看到用 $9 \times 9$ 的框去crop出这个image segment的话，绿色的内容会相对更多一点。</p>
<p>作者在Section 3.2的最后一段也提到，这个segments size在模型中是一个超参数，提到segment size会提升模型的性能，但是很快这种性能的提升久会达到平稳(level off)，并且在一系列的segment size中都会得到相似的性能。</p>
<h1 id="3-构建更深的网络"><a href="#3-构建更深的网络" class="headerlink" title="3. 构建更深的网络"></a>3. 构建更深的网络</h1><blockquote>
<p>该部分总结：Deeper Networks + Smaller Kernel + Batch Norm + (p)ReLU + $ \mathcal{N}\left(0,\ \sqrt{2/n^{in}_{l}} \right)$</p>
</blockquote>
<p>更深的网络有更好的判别能力，但是更深的网络同时意味着更高的计算代价和更吃内存。所以在这里作者采用的策略是层数增加，但是把kernel size从 $5^3$ 缩小到 $3^3$ 从而减少计算代价和节省内存。作者认为这里kernel size减小说明需要训练的parameters的数量减少，一定程度上有正则的效果。（但是原文好像只是给了个简单的  $\frac{5^3}{3^3} \approx 4.6$，但是层数的增加会增加参数的数量，不知道作者有没有算对，我也没去算它….）</p>
<p>因为更深的网络变得容易train不下去，所以作者采用了 ReLU-based 的网络 (在github文件看，DeepMedic的网络好像采用的是pReLU)。同时，作者不采用标准正态分布去初始化kernel weights，才是采用了 $ \mathcal{N}\left(0,\ \sqrt{2/n^{in}_{l}} \right)$ 。</p>
<p>Batch Normalisation</p>
<h1 id="4-Dual-Pathways-Networks"><a href="#4-Dual-Pathways-Networks" class="headerlink" title="4. Dual Pathways Networks"></a>4. Dual Pathways Networks</h1><p><br/><br/></p>
<p><img src="https://ars.els-cdn.com/content/image/1-s2.0-S1361841516301839-gr5_lrg.jpg" alt="Fig.5. Multi-scale 3D CNN with two convolutional pathways. The kernels of the two pathways are here of size $5^3$ (for illustration only to reduce the number of layers in the figure). The neurons of the last layers of the two pathways thus have receptive fields of size $17^3$ voxels. The inputs of the two pathways are centred at the same image location, but the second segment is extracted from a down-sampled version of the image by a factor of 3. The second pathway processes context in an actual area of size $51^3$ voxels. DeepMedic, our proposed 11-layers architecture, results by replacing each layer of the depicted pathways with two that use $3^3$ kernels (see Section 2.3). Number of FMs and their size depicted as (Number × Size)."></p>
<p>作者为上述deeper networks增加了第二个pathway networks，对down-sampling的图像进行操作。这种dual pathways 3D CNN 同时对高/低分辨率图像进行训练，文中提到第二个网络(低分辨率)用于捕捉一些high level的信息，例如 location。而第一个网络（高分辨率）用于捕捉一些细节信息。为了使得最后输出的feature maps尺寸一致，要对第二个网络的输出进行上采样以匹配第一个网络输出的feature maps的尺寸。</p>
<h1 id="5-3D-fully-connected-CRF"><a href="#5-3D-fully-connected-CRF" class="headerlink" title="5. 3D fully connected CRF"></a>5. 3D fully connected CRF</h1><p>作者认为CNN网络输出的结果偏向与smooth（如何smooth可以见下图），因此对DeepMedic网络（11层，dual pathways）网络的输出认为是soft segmentation。最后作者用CRF对soft segmentations 进行后处理（post-processing）改善其边缘信息。<br><br/><br/></p>
<p><img src="/Documents/deepmedic/smooth.png" alt=""></p>
<h2 id="5-1-为什么CRF可以用于处理图像任务？"><a href="#5-1-为什么CRF可以用于处理图像任务？" class="headerlink" title="5.1 为什么CRF可以用于处理图像任务？"></a>5.1 为什么CRF可以用于处理图像任务？</h2><p>首先对于图像任务，我们可以把每个像素认为是一个单独的节点（node），像素与像素之间就构成了边（edge），同时，相邻像素之间相互影响，而这种影响是对称的，相当于edge，因此构成了一个概率无向图。</p>
<h2 id="5-2-全连接条件随机场"><a href="#5-2-全连接条件随机场" class="headerlink" title="5.2 全连接条件随机场"></a>5.2 全连接条件随机场</h2><p>对于每个像素 $i$ 具有类别标签 $x_i$ 还有对应的观测值 $y_i$，这样每个像素点作为节点，像素与像素间的关系作为边，即构成了一个条件随机场。而且我们通过观测变量 $y_i$ 来推测像素 $i$ 对应的类别标签 $x_i$。条件随机场如下：</p>
<p><img src="/Documents/deepmedic/CRF.png" alt=""></p>
<p>条件随机场符合吉布斯分布：(此处的 $x$ 即上面说的观测值)<br>
$$P(\boldsymbol{X} = \mathbf{x} | \boldsymbol{I}) = \frac{1}{Z(\boldsymbol{I})} exp\left( -\mathbb{E}(\mathbf{x}|\boldsymbol{I}) \right) $$
</p>
<p>其中的 $\mathbb{E}(\mathbf{x}|\boldsymbol{I})$ 是能量函数，为了简便，以下省略全局观测 $\boldsymbol{I}$：</p>

$$
E(\mathbf{x})=\sum_i{\Psi_u(x_i)}+\sum_{i,j}\Psi_p(x_i, x_j)
$$

<p>其中的一元势函数 $\sum_i{\Psi_u(x_i)}$ 即来自于前端FCN的输出。而二元势函数如下：</p>

$$\Psi_p(x_i, x_j)=u(x_i, x_j)\sum_{m=1}^M{\omega^{(m)}k_G^{(m)}(\boldsymbol{f_i, f_j)}}$$

<p>二元势函数就是描述像素点与像素点之间的关系，鼓励相似像素分配相同的标签，而相差较大的像素分配不同标签，而这个“距离”的定义与颜色值和实际相对距离有关。所以这样CRF能够使图片尽量在边界处分割。</p>
<p>而全连接条件随机场的不同就在于，二元势函数描述的是每一个像素与其他所有像素的关系，所以叫“全连接”。</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol>
<li><p>Harvard Referencing: Kamnitsas, K., Ledig, C., Newcombe, V.F., Simpson, J.P., Kane, A.D., Menon, D.K., Rueckert, D. and Glocker, B., 2017. Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation. Medical image analysis, 36, pp.61-78. </p>
</li>
<li><p><a href="https://yq.aliyun.com/articles/232455">https://yq.aliyun.com/articles/232455</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/22308032">https://zhuanlan.zhihu.com/p/22308032</a></p>
</li>
</ol>
</div><ul class="post-copyright"><li><strong>Title: </strong><a href="/2019/07/18/deepmedic/">DeepMedic - multi-sacle 3D CNN with CRF for brain lesion segmentation</a></li><li><strong>Author: </strong><a href="/">Zhanhang ZENG (展航)</a></li><li><strong>Link: </strong><a href="/2019/07/18/deepmedic/">https://zengzhanhang.github.io/2019/07/18/deepmedic/</a></li><li><strong>Released Date: </strong>2019-07-18</li><li><strong>Last update: </strong>2020-05-16</li><li><strong>Statement: </strong>All articles in this blog, unless otherwise stated, are based on the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> license.</li></ul><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex mb-4"><div class="level-start"><div class="article-tags size-small is-uppercase"><span class="mr-2"><i class="fas fa-tags has-text-grey"></i> #</span><a class="link-muted mr-2" rel="tag" href="/tags/CV/">CV</a><a class="link-muted mr-2" rel="tag" href="/tags/Image-Segmentation/">Image Segmentation</a><a class="link-muted mr-2" rel="tag" href="/tags/Medical-Imaging/">Medical Imaging</a><a class="link-muted mr-2" rel="tag" href="/tags/Reading-Note/">Reading Note</a></div></div><div class="level-start"><div style="text-align:center"></div></div></div><div style="text-align:center"><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=5ebfed406b62a000122baf21&amp;product=inline-share-buttons" defer></script></div></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/img/QRcode/alipay.jpg" alt="Alipay"></span></a><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/img/QRcode/WeChatPay.jpg" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2019/07/21/densenet/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">DenseNet — Dense卷积网络（图像分类）</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/06/12/Keras-notes/"><span class="level-item">Keras 笔记</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: '53070330a13f7548f94c3421817f4801',
            repo: 'zengzhanhang.github.io',
            owner: 'zengzhanhang',
            clientID: '13624a11c95a2d5eed31',
            clientSecret: '67d97a17e7f385cf24a8a24e3bbfaa1e8fcc20c4',
            admin: ["zengzhanhang"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 10,
            pagerDirection: 'last',
            
            
            enableHotKey: true
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="is-rounded" src="/img/icon(square)-min.png" alt="Zhanhang (Kyle) Zeng"></figure><p class="title is-size-4 is-block line-height-inherit">Zhanhang (Kyle) Zeng</p><p class="is-size-6 is-block">Statistics, Machine Learning &amp; Ai</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Edinburgh, the United Kingdom</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">13</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">11</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">17</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded follow-button" href="https://github.com/zengzhanhang" target="_blank" rel="noopener"><i class="fab fa-github"></i>  Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Linkedin" href="https://www.linkedin.com/in/zhanhang-zeng-801a67185/"><i class="fab fa-linkedin-in"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/zengzhanhang"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://www.facebook.com/zengzhanhang"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Instagram" href="https://www.instagram.com/cengzhanhang"><i class="fab fa-instagram"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://www.weibo.com/zengzhanhang"><i class="fab fa-weibo"></i></a></div></div></div><div class="card widget is-sticky" id="toc"><div class="card-content"><div class="menu catalogue-other-setting"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="is-flex" href="#1-Dense-Training"><span class="mr-2">1</span><span>1. Dense Training</span></a></li><li><a class="is-flex" href="#2-Class-Balance"><span class="mr-2">2</span><span>2. Class Balance</span></a></li><li><a class="is-flex" href="#3-构建更深的网络"><span class="mr-2">3</span><span>3. 构建更深的网络</span></a></li><li><a class="is-flex" href="#4-Dual-Pathways-Networks"><span class="mr-2">4</span><span>4. Dual Pathways Networks</span></a></li><li><a class="is-flex" href="#5-3D-fully-connected-CRF"><span class="mr-2">5</span><span>5. 3D fully connected CRF</span></a><ul class="menu-list"><li><a class="is-flex" href="#5-1-为什么CRF可以用于处理图像任务？"><span class="mr-2">5.1</span><span>5.1 为什么CRF可以用于处理图像任务？</span></a></li><li><a class="is-flex" href="#5-2-全连接条件随机场"><span class="mr-2">5.2</span><span>5.2 全连接条件随机场</span></a></li></ul></li><li><a class="is-flex" href="#Reference"><span class="mr-2">6</span><span>Reference</span></a></li></ul></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo1.png" alt="小树的面包店 | ZhanhangZeng&#039;s Blog" height="28"></a><p class="size-small"><span>&copy; 2020 Zhanhang ZENG (展航)</span>  All Rights Reserved<br>Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span>    <span id="busuanzi_container_site_pv">Totally, <span id="busuanzi_value_site_pv">0</span> page views</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="fab fa-creative-commons"></i> <i class="fab fa-creative-commons-by"></i> <i class="fab fa-creative-commons-nc"></i> <i class="fab fa-creative-commons-sa"></i> </a><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Zhanhang&#039;s GitHub" href="https://github.com/zengzhanhang"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://zengzhanhang.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>